---
title: 빅데이터 - 데이터 팀
category: Programmers 인공지능 데브코스
tags: [
    Big Data
]
---

# 빅데이터

- 데이터 팀
    - 역할
    - 구성원
    - 조직구조
- 모델 개발 시 고려할 점
- 데이터 관련 교훈

## 데이터 팀의 역할

- 데이터 팀의 미션
    - **신뢰할 수 있는 데이터**를 바탕으로 부가가치 생성

- 데이터 팀의 목표
    - **정책 결정에 사용**
        - 결정과학(Decision Science)라고 부르기도 함
            - **데이터 참고 결정**(data informed decisions)을 가능하게 함
    - 사용자의 서비스 경험 개선
        - 머신 러닝과 같은 데이터 기반 알고리즘을 통해 개선
            - 개인화를 바탕으로 추천과 검색 기능 제공
            - 사람의 개입/도움이 필요

### 1. 데이터 인프라 구축

데이터 인프라 : 데이터 웨어하우스와 ETL

데이터 웨어하우스란?

: 회사에 필요한 모든 데이터를 모아놓은 중앙 데이터베이스 (SQL)

- 데이터의 크기에 맞게 어떤 데이터베이스를 사용할 지 선택

ETL(Extract, Transform, Load) 이란?

: 소스에 존재하는 데이터들을 데이터 웨어하우스로 복사해오는 코드를 지칭

- Extract : 외부 데이터 소스에서 데이터를 추출
- Transform : 데이터의 포맷을 원하는 형태로 변환
- Load : 변환된 데이터를 최종적으로 데이터 웨어하우스로 적재

### 2. 데이터 분석 수행

데이터 분석이란?

: 회사와 팀별 중요 지표(metrics)를 정의하고 대시보스 형태로 **시각화**(visualization) (중요지표 예: 매출액, 월간 사용자 수 등)

: 이외에도 데이터와 관련한 다양한 분석/리포팅 업무 수행

시각화 대시보드

: 보통 중요한 지표를 시간의 흐름과 보여줌

- 지표의 경우 3A(Accessible, Actionable, Auditable)가 중요

### 3. 머신러닝/인공지능 적용

데이터 인프라에 저장된 데이터를 기반으로 지도학습을 통해 머신러닝 모델들을 개발하여 추천, 검색 등을 개인화하는 것이 일반적인 패턴

## 데이터 팀의 구성원

- 데이터 엔지니어 (Data Engineer)
    - 데이터 인프라 구축 (데이터 웨어하우스, ETL)
- 데이터 분석가 (Data Analyst)
    - 데이터 웨어하우스의 데이터를 기반으로 지표를 만들고 시각화 (대시보드)
- 데이터 과학자 (Data Scientist)
    - 과거 데이터를 기반으로 미래를 예측하는 머신러닝 모델을 만들어 고객들의 서비스 경험을 개선 (개인화, 자동화, 최적화 등)

> 작은 회사에서는 한 사람이 몇개의 역할을 동시에 수행하기도 한다...

### 데이터 엔지니어

- 기본적으로 소프트웨어 엔지니어
    - 보통은 파이썬 사용. 자바 혹은 스칼라와 같은 언어도 아는 것이 좋음
- 데이터 인프라 구축
    - 데이터 웨어하우스를 만들고 이를 관리 (보통 클라우드 사용)
        - 예) AWS의 Redshift, 구글 클라우드의 BigQuery, 스노우플레이크(Snowflake)나 오픈 소스 기반의 Hadoop/Spark
    - ETL 코드를 작성하고 주기적으로 실행
        - 예) 스케줄러로 Airflow 사용
        - (Airflow는 오픈소스 프로젝트로 파이썬 3 기반이며 에어비앤비, 우버, 리프트, 쿠팡 등에서 사용)
- 데이터 분석가와 과학자 지원

### 데이터 분석가

- 비즈니스 인텔리전스를 책임
    - 중요 지표를 정의하고 이를 대시보드 형태로 시각화
        - 예) 대시보드 - 태블로(Tableau), 룩커(Looker) / 오픈소스 - 수퍼셋(Superset) 을 많이 사용
- 회사 내 다른 팀들의 데이터 관련 질문 대답
- 필요한 스킬셋
    - SQL, 통계적 지식
    - 비즈니스 도메인에 관한 깊은 지식 💡
    - 보통 코딩은 하지 않음

### 데이터 과학자

- 머신러닝 형태로 사용자들의 경험을 개선
    - 문제에 맞춰 가설을 세우고 데이터를 수집한 후에 예측 모델을 만들고 이를 테스트
    - 테스트는 가능하면 **A/B 테스트**를 수행하는 것이 좋음
- 필요한 스킬셋
    - 머신러닝/인공지능에 대한 깊은 지식과 경험
    - 코딩 능력 (파이썬과 SQL)
    - 통계 지식, 수학 지식 (통계 > 수학)
    - ⭐끈기와 열정 (박사 학위가 도움이 되는 이유 중의 하나)

📌

A/B 테스트란?

: 온라인 서비스에서 새 기능의 임팩트를 객관적으로 측정하는 방법

- 새로운 기능을 론치함으로 생기는 위험부담을 줄이는 방법
    - 100%를 론치하는 것이 아니라 작게 시작하고 관찰 후 결정
    - 예) 먼저 5%의 사용자에게만 론치하고 나머지 95%의 사용자와 중요 지표를 비교 → 별 문제 없으면 10%, 20% 점진적으로 키워감
- 2개의 그룹으로 나누고 시간을 두고 관련 지표를 비교
    - 두 그룹의 특성은 비슷해야한다.
- 가설에 영향을 주는 지표를 미리 정하고 시작

## 데이터 팀의 조직구조

- 중앙집중 구조: 모든 데이터 팀원들이 하나의 팀으로 존재
    - 일의 우선 순위는 중앙 데이터팀이 최종 결정
    - 데이터 팀원들간의 지식과 경험의 공유가 쉬워지고 커리어 경로가 더 잘 보임
    - 현업 부서의 만족도가 떨어짐
- 분산 구조: 데이터 팀이 현업 부서별로 존재
    - 일의 우선순위는 각 팀별로 결정
    - 지식과 경험의 공유가 힘들고 데이터 인프라나 데이터 공유가 힘들어짐
    - 현업 부서의 만족도는 처음에는 좋지만 갈수록 힘들어짐

- 중앙집중과 분산의 하이드리드 모델
    - 가장 이상적인 조직 구조
    - 데이터 팀원들은 일부는 중앙에서 인프라적인 일을 수행하고, 일부는 현업팀으로 파견식으로 일하되 주기적으로 일을 변경

## 모델 개발 시 고려할 점

- 누군가 모델 개발부터 최종 론치까지 책임질 사람이 필요
- 모델 개발 초기부터 개발/론치 과정을 구체화하고 소통
    - 모델을 어떻게 검증할 것인지?
    - 모델을 어떤 형태로 엔지니어들에게 넘길 것인지?
    - 모델을 프로덕션에서 A/B 테스트할 것인지?
- 개발된 모델이 바로 프로덕션에서 론치가능한 프로세스/프레임워크가 필요
    - 예) R로 개발된 모델은 바로 프로덕션 론치 불가능

- 첫 모델 론치는 시작일 뿐 → 운영을 통해 점진적인 개선을 하는 것이 중요
    - 피드팩 루프 필요
        - 운영에서 생기는 데이터를 가지고 개선점 찾기
            - 검색이라면 CTR(Click Through Rate)을 모니터링하고 모든 데이터를 기록
        - 주기적으로 모델 재빌딩
            - 온라인 러닝 : 모델이 프로덕션에서 사용되면서 계속적으로 업데이트 되는 방식의 머신러닝
- 수익 증대 필요
    - 데이터를 통해 회사 수익에 긍정적인 영향을 주어야 함

- 데이터 인프라
    - 데이터 인프라 없이는 데이터 분석이나 모델링 불가능
    - 고려할 점
        - 클라우드 vs 직접 구성
        - 배치 vs 실시간
- 데이터 품질
    - 데이터 청소 작업 중요 (데이터 품질 유지에 노력 필요)
- 중요 지표
    - 지표를 세우는 것이 중요
    - 지표의 계산에 있어서 객관성이 중요

🔥 간단한 솔루션으로 시작하는 것이 좋다. (한 큐에 모델을 완성하는 것 보다는 반복 기반의 점전적인 개발방식이 더 좋다)

📌 요약

- 데이터 팀의 목표는 신뢰할 수 있는 데이터를 바탕으로 부가가치를 생성하는 것이다.
- 데이터 직군에는 엔지니어, 분석가, 과학가 이렇게 세 종류가 존재한다.
- 데이터 팀 조직 구조에는 중앙집중, 분산, 하이브리드의 세 종류가 존재한다.
- 모델 개발은 **론치와 운영**에 초점을 맞춰야 한다.
- 데이터 팀의 존재 여부는 수익 증대이다.
- 단순한 솔루션이 제일 좋은 솔루션이다. (모든 문제에 딥러닝 사용 ❌)
